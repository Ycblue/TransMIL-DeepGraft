{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import zarr\n",
    "from numcodecs import Blosc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ResNet as ResNet \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from imgaug import augmenters as iaa\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_parse():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--augment', default=False, action='store_true')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def get_coords(batch_names): #ToDO: Change function for precise coords\n",
    "    coords = []\n",
    "    \n",
    "    for tile_name in batch_names: \n",
    "        # print(tile_name)\n",
    "        pos = re.findall(r'\\((.*?)\\)', tile_name)\n",
    "        x, y = pos[-1].split('_')\n",
    "        coords.append((int(x),int(y)))\n",
    "    return coords\n",
    "\n",
    "def iaa_augment(img):\n",
    "\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug, name=\"Random1\")\n",
    "    sometimes2 = lambda aug: iaa.Sometimes(0.2, aug, name=\"Random2\")\n",
    "    sometimes3 = lambda aug: iaa.Sometimes(0.9, aug, name=\"Random3\")\n",
    "    sometimes4 = lambda aug: iaa.Sometimes(0.9, aug, name=\"Random4\")\n",
    "    sometimes5 = lambda aug: iaa.Sometimes(0.9, aug, name=\"Random5\")\n",
    "\n",
    "    transforms = iaa.Sequential([\n",
    "        iaa.AddToHueAndSaturation(value=(-30, 30), name=\"MyHSV\"), #13\n",
    "        sometimes2(iaa.GammaContrast(gamma=(0.85, 1.15), name=\"MyGamma\")),\n",
    "        iaa.Fliplr(0.5, name=\"MyFlipLR\"),\n",
    "        iaa.Flipud(0.5, name=\"MyFlipUD\"),\n",
    "        sometimes(iaa.Rot90(k=1, keep_size=True, name=\"MyRot90\")),\n",
    "        iaa.OneOf([\n",
    "            sometimes3(iaa.PiecewiseAffine(scale=(0.015, 0.02), cval=0, name=\"MyPiece\")),\n",
    "            sometimes4(iaa.ElasticTransformation(alpha=(100, 200), sigma=20, cval=0, name=\"MyElastic\")),\n",
    "            sometimes5(iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)}, rotate=(-45, 45), shear=(-4, 4), cval=0, name=\"MyAffine\"))\n",
    "        ], name=\"MyOneOf\")\n",
    "    ])\n",
    "    seq_img_d = transforms.to_deterministic()\n",
    "    img = seq_img_d.augment_image(img)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--augment]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9040 --control=9038 --hb=9037 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"fea321c1-c51d-4123-ac4e-21d7b6f0be68\" --shell=9039 --transport=\"tcp\" --iopub=9041 --f=/home/ylan/.local/share/jupyter/runtime/kernel-v2-8466dCu9m1xIy2SG.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(8)\n",
    "torch.manual_seed(2022)\n",
    "\n",
    "args = make_parse()\n",
    "\n",
    "augment=args.augment\n",
    "print('Augment Data: ', augment)\n",
    "\n",
    "home = Path.cwd().parts[1]\n",
    "data_root = Path(f'/{home}/ylan/data/DeepGraft/tissue_detection/224_128uM/images')\n",
    "slide_patient_path = f'/{home}/ylan/DeepGraft/training_tables/slide_patient_dict.json'\n",
    "cohort_stain_path = f'/{home}/ylan/DeepGraft/training_tables/cohort_stain_dict.json'\n",
    "with open(slide_patient_path, 'r') as f:\n",
    "    slide_patient_dict = json.load(f)\n",
    "with open(cohort_stain_path, 'r') as f:\n",
    "    cohort_stain_dict = json.load(f)\n",
    "# output_path = Path(f'/{home}/ylan/wsi_tools/debug/zarr')\n",
    "# cohorts = ['DEEPGRAFT_RU'] #, \n",
    "# cohorts = ['Aachen_Biopsy_Slides'] #, \n",
    "# cohorts = ['Aachen_Biopsy_Slides', 'DEEPGRAFT_RU', 'DEEPGRAFT_RA', 'Leuven'] #, \n",
    "compressor = Blosc(cname='blosclz', clevel=3)\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "        # \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        ),\n",
    "        # RangeNormalization(),\n",
    "    ])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "n_classes = 2\n",
    "# out_features = 1024\n",
    "model_ft = ResNet.resnet50(num_classes=128, mlp=False, two_branch=False, normlinear=True)\n",
    "\n",
    "model_ft.fc = nn.Identity()\n",
    "# print(model_ft)\n",
    "# model_ft.fc = nn.Linear(2048, out_features)\n",
    "home = Path.cwd().parts[1]\n",
    "model_ft.load_state_dict(torch.load(f'/{home}/ylan/workspace/TransMIL-DeepGraft/code/models/ckpt/retccl_best_ckpt.pth'), strict=True)\n",
    "# for param in model_ft.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for m in model_ft.modules():\n",
    "#     if isinstance(m, torch.nn.modules.batchnorm.BatchNorm2d):\n",
    "#         m.eval()\n",
    "#         m.weight.requires_grad = False\n",
    "#         m.bias.requires_grad = False\n",
    "# model_ft.fc = nn.Linear(2048, out_features)\n",
    "model_ft.eval()\n",
    "model_ft.to(device)\n",
    "\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "patient_cohort_dict = {}\n",
    "for cohort in cohort_stain_dict.keys():\n",
    "    cohort_patient_list = list(cohort_stain_dict[cohort].keys())\n",
    "    for patient in cohort_patient_list:\n",
    "        patient_cohort_dict[patient] = cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in data_root.iterdir():\n",
    "    slide_name = f.stem.split('_', 1)[0]\n",
    "    patient = slide_patient_dict[slide_name]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b7fb95db5714bbf59d6a04f6057e8fa5746fef9d16f5c42f2fdbc713170171a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
